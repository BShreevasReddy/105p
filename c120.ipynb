{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c120",
      "provenance": [],
      "authorship_tag": "ABX9TyMJaY5WXNu0jsmiWu8QLWBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BShreevasReddy/105p/blob/main/c120.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsC1Pvra8m_g"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAIVE BAYES**\n",
        "\n",
        "Naive Bayes algorithm is a supervised machine learning algorithm based on the Bayes Probability theorem. Naive Bayes assumes that there is no correlation between the features in a dataset used to train the model. We will get back to this later. Despite the oversimplified assumptions, Naive Bayes works very well in many real world complex problems. They require a relatively small number of training data samples to perform classification efficiently, compared to other algorithms like Logistic Regression and Decision trees, that we studied earlier.\n",
        "\n",
        "\n",
        "\n",
        "**BAYES THEOREM**\n",
        "\n",
        "Bayes theorem describes the probability of a feature, based on prior knowledge of situations related to that feature. For example, if the probability someone having diabetes is related to his or her age, then by using the Bayes Theorem, the age can be used to more accurately predict the probability of having diabetes.\n",
        "\n",
        "\n",
        "\n",
        "**NAIVE**\n",
        "\n",
        "The word naive implies that every pair of features in the dataset is independent of each other. Naive Bayes works on the assumption that the value of a particular feature is independent of any other feature. For example, A vegetable may be classified as a tomato if it's round, about 4 cm in diameter, and red in color. With Naive Bayes, each of these three features (shape, size and color) contributes independently to the probability that the vegetable is a tomato. Also, it assumes that there is no possible correlation between the shape, size and color.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-_Os4lF88c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/c120(1).csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEd9z3_HAops",
        "outputId": "247afc21-028e-4f48-e481-210437c44ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   glucose  bloodpressure  diabetes\n",
            "0       40             85         0\n",
            "1       40             92         0\n",
            "2       45             63         1\n",
            "3       45             80         0\n",
            "4       40             73         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[[\"glucose\",\"bloodpressure\"]]\n",
        "Y = df[\"diabetes\"]\n",
        "x_train_1,x_test_1,y_train_1,y_test_1 = train_test_split(X, Y, test_size=0.25, random_state = 42)"
      ],
      "metadata": {
        "id": "20Txs2-hBctB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train_1 = sc.fit_transform(x_train_1)\n",
        "x_test_1 = sc.fit_transform(x_test_1)\n",
        "\n",
        "model_1 = GaussianNB()\n",
        "model_1.fit(x_train_1, y_train_1)\n",
        "\n",
        "y_pred_1 = model_1.predict(x_test_1)\n",
        "\n",
        "accuracy = metrics.accuracy_score(y_test_1, y_pred_1)\n",
        "print(accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "snkPAoDjCnxN",
        "outputId": "9162ab2f-bc8d-4adc-b2a2-a6b986cc4a02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a6e6234b1f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx_test_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance.\n",
        "Unit variance means dividing all the values by the standard deviation."
      ],
      "metadata": {
        "id": "KzMCPJo2D8A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[[\"glucose\",\"bloodpressure\"]]\n",
        "Y = df[\"diabetes\"]\n",
        "x_train_2,x_test_2,y_train_2,y_test_2 = train_test_split(X, Y, test_size=0.25, random_state = 42)"
      ],
      "metadata": {
        "id": "5Cf6K4oCEncB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train_2 = sc.fit_transform(x_train_2)\n",
        "x_test_2 = sc.fit_transform(x_test_2)\n",
        "\n",
        "model_2 = LogisticRegression(random_state = 0)\n",
        "model_2.fit(x_train_2, y_train_2)\n",
        "\n",
        "y_pred_2 = model_2.predict(x_test_2)\n",
        "\n",
        "accuracy = accuracy_score(y_test_2, y_pred_2)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2_G0fGIE35L",
        "outputId": "c15e3161-d25f-411f-fce3-7c9ea5ccbc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9156626506024096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/c120income.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXS-rhdQF4_F",
        "outputId": "5c02cf55-d2ac-4c2b-b820-ed5af1a34aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age          workclass education_level  education-num       marital-status  \\\n",
            "0   39          State-gov       Bachelors           13.0        Never-married   \n",
            "1   50   Self-emp-not-inc       Bachelors           13.0   Married-civ-spouse   \n",
            "2   38            Private         HS-grad            9.0             Divorced   \n",
            "3   53            Private            11th            7.0   Married-civ-spouse   \n",
            "4   28            Private       Bachelors           13.0   Married-civ-spouse   \n",
            "\n",
            "           occupation    relationship    race      sex  capital-gain  \\\n",
            "0        Adm-clerical   Not-in-family   White     Male        2174.0   \n",
            "1     Exec-managerial         Husband   White     Male           0.0   \n",
            "2   Handlers-cleaners   Not-in-family   White     Male           0.0   \n",
            "3   Handlers-cleaners         Husband   Black     Male           0.0   \n",
            "4      Prof-specialty            Wife   Black   Female           0.0   \n",
            "\n",
            "   capital-loss  hours-per-week  native-country income  \n",
            "0           0.0            40.0   United-States  <=50K  \n",
            "1           0.0            13.0   United-States  <=50K  \n",
            "2           0.0            40.0   United-States  <=50K  \n",
            "3           0.0            40.0   United-States  <=50K  \n",
            "4           0.0            40.0            Cuba  <=50K  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[[\"age\",\"hours-per-week\",\"education-num\",\"capital-gain\",\"capital-loss\"]]\n",
        "Y = df[\"income\"]\n",
        "x_train_1,x_test_1,y_train_1,y_test_1 = train_test_split(X, Y, test_size=0.25, random_state = 42)"
      ],
      "metadata": {
        "id": "eTS-j48_F-zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train_1 = sc.fit_transform(x_train_1)\n",
        "x_test_1 = sc.fit_transform(x_test_1)\n",
        "\n",
        "model_1 = GaussianNB()\n",
        "model_1.fit(x_train_1, y_train_1)\n",
        "\n",
        "y_pred_1 = model_1.predict(x_test_1)\n",
        "\n",
        "accuracy = accuracy_score(y_test_1, y_pred_1)\n",
        "print(accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjNalmwwGm8R",
        "outputId": "cdc36df6-9747-4026-a0b7-4d94221ecc86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7896692021935255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[[\"age\",\"hours-per-week\",\"education-num\",\"capital-gain\",\"capital-loss\"]]\n",
        "Y = df[\"income\"]\n",
        "x_train_4,x_test_4,y_train_4,y_test_4 = train_test_split(X, Y, test_size=0.25, random_state = 42)"
      ],
      "metadata": {
        "id": "nDGceDuwGy1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train_4 = sc.fit_transform(x_train_4)\n",
        "x_test_4 = sc.fit_transform(x_test_4)\n",
        "\n",
        "model_4 = LogisticRegression(random_state = 0)\n",
        "model_4.fit(x_train_4, y_train_4)\n",
        "\n",
        "y_pred_4 = model_4.predict(x_test_4)\n",
        "\n",
        "accuracy = accuracy_score(y_test_4, y_pred_4)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5soOs8d5GzjM",
        "outputId": "3a7d57b6-3be7-48bd-824d-2f1aaec84ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8116929064213692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dibvGLkSGzsK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}